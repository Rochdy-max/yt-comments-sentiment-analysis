services:
  # Airflow PostgreSQL Database
  airflow_db:
    image: postgres:16.0
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    logging:
      options:
        max-size: 10m
        max-file: "3"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  # Airflow Init
  airflow_init:
    extends:
      file: base-services.yml
      service: airflow_common_base
    entrypoint: bash -c "airflow db init && airflow users create --role Admin --username admin --email admin --firstname admin --lastname admin --password admin"
    depends_on:
      - airflow_db
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Airflow Webserver
  airflow_webserver:
    extends:
      file: base-services.yml
      service: airflow_common_base
    entrypoint: bash -c "airflow db upgrade && airflow webserver"
    restart: always
    depends_on:
      - airflow_init
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Airflow Scheduler
  airflow_scheduler:
    extends:
      file: base-services.yml
      service: airflow_common_base
    entrypoint: bash -c "airflow db upgrade && airflow scheduler"
    restart: always
    depends_on:
      - airflow_webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-scheduler.pid ]"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres-db-volume:
  spark_data: